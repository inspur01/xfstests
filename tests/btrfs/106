#! /bin/bash
# FSQA Test No. 106
#
# Regression test for file read corruption when using compressed extents
# that represent file ranges with a length that is a multiple of 16 pages
# and that are shared by multiple consecutive ranges of the same file.
#
#-----------------------------------------------------------------------
#
# Copyright (C) 2015 SUSE Linux Products GmbH. All Rights Reserved.
# Author: Filipe Manana <fdmanana@suse.com>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it would be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write the Free Software Foundation,
# Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
#-----------------------------------------------------------------------
#

seq=`basename $0`
seqres=$RESULT_DIR/$seq
echo "QA output created by $seq"
tmp=/tmp/$$
status=1	# failure is the default!
trap "_cleanup; exit \$status" 0 1 2 3 15

_cleanup()
{
	cd /
	rm -f $tmp.*
}

# get standard environment, filters and checks
. ./common/rc
. ./common/filter

# real QA test starts here
_supported_fs btrfs
_supported_os Linux
_require_scratch
_require_cloner

rm -f $seqres.full

test_clone_and_read_compressed_extent()
{
	local mount_opts=$1

	_scratch_mkfs >>$seqres.full 2>&1
	_scratch_mount $mount_opts

	PAGE_SIZE=$(get_page_size)

	# Create our test file with 16 pages worth of data in a single extent
	# that is going to be compressed no matter which compression algorithm
	# is used (zlib/lzo).
	$XFS_IO_PROG -f -c "pwrite -S 0xaa 0K $((16 * $PAGE_SIZE))" \
		     $SCRATCH_MNT/foo | _filter_xfs_io_pages_modified

	# Now clone the compressed extent into an adjacent file offset.
	$CLONER_PROG -s 0 -d $((16 * $PAGE_SIZE)) -l $((16 * $PAGE_SIZE)) \
		$SCRATCH_MNT/foo $SCRATCH_MNT/foo

	echo "File contents before unmount:"
	od -t x1 $SCRATCH_MNT/foo | _filter_od

	# Remount the fs or clear the page cache to trigger the bug in btrfs.
	# Because the extent has an uncompressed length that is a multiple of 16
	# pages, all the pages belonging to the second range of the file that is
	# mapped by the page index range [16, 31], which points to the same
	# extent as the first file range mapped by the page index range [0, 15],
	# had their contents full of zeroes instead of the byte 0xaa. This was a
	# bug exclusively in the read path of compressed extents, the correct
	# data was stored on disk, btrfs just failed to fill in the pages
	# correctly.
	_scratch_cycle_mount

	echo "File contents after remount:"
	# Must match the digest we got before.
	od -t x1 $SCRATCH_MNT/foo | _filter_od
}

echo -e "\nTesting with zlib compression..."
test_clone_and_read_compressed_extent "-o compress=zlib"

_scratch_unmount

echo -e "\nTesting with lzo compression..."
test_clone_and_read_compressed_extent "-o compress=lzo"

status=0
exit
